{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future improvements\n",
    "# Create JSON array to assign IDs, \n",
    "#     keep track of PDF files process (each step?) etc.\n",
    "# Implement 'fi'/'fl' check at beginning and end of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time, sys\n",
    "import PyPDF2\n",
    "from datetime import datetime, date\n",
    "import decimal\n",
    "import re\n",
    "import spacy\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "txtFilesDir = 'Text Files'\n",
    "absolute = 'C:/Users/micah/Documents/IWU/CIS Practicum/Files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on 'A  cognitive affective model of organizational communication for designing IT.pdf'. . . \"A  cognitiv\"... already exists\n",
      "\n",
      "Now on 'A Bible for the Disability Field.pdf'. . . \"A Bible for\"... already exists\n",
      "\n",
      "Now on 'A Comparisoon of Binarization Methods for Historical Archive Documents.pdf'. . . \"A Compariso\"... already exists\n",
      "\n",
      "Now on 'A light-weight text image processing method for handheld embedded cameras.pdf'. . . \"A light-wei\"... already exists\n",
      "\n",
      "Now on 'A Mathematical Theory of Communication.pdf'. . . there was an error reading this document. See log for details. Reference number 5.\n",
      "\n",
      "Now on 'A Model for Types and Levels of Human Interaction with Automation.pdf'. . . \"A Model for\"... already exists\n",
      "\n",
      "Now on 'A Parser for Real-Time Speech Synthesis of Conversational Texts.pdf'. . . \"A Parser fo\"... already exists\n",
      "\n",
      "Now on 'A Physically Based Approach to 2-D Shape Blending.pdf'. . . there was an error reading this document. See log for details. Reference number 8.\n",
      "\n",
      "Now on 'A Review of 326 Children with Developmental and Physical Disabilities, Consecutively Taught at the Movement Development Clinic.pdf'. . . \"A Review of\"... already exists\n",
      "\n",
      "Now on 'A Review of Quasi-Linear Pilot Models.pdf'. . . \"A Review of\"... already exists\n",
      "\n",
      "Now on 'A Set of C++ Classes for Co-routine Style Programming.pdf'. . . \"A Set of C+\"... already exists\n",
      "\n",
      "Now on 'A Spiral Model of Software Development and Enhancement.pdf'. . . there was an error reading this document. See log for details. Reference number 12.\n",
      "\n",
      "Now on 'A Study of Design Requirements for Mobile Learning Environments.pdf'. . . \"A Study of \"... already exists\n",
      "\n",
      "Now on 'A Target Tracking Algorithm of Passive Sensor Normal Truncated Model.pdf'. . . \"A Target Tr\"... already exists\n",
      "\n",
      "Now on 'a12.pdf'. . . \"a12.txt\" already exists\n",
      "\n",
      "Now on 'a2-jeong.pdf'. . . \"a2-jeong.tx\"... already exists\n",
      "\n",
      "Now on 'a2.pdf'. . . \"a2.txt\" already exists\n",
      "\n",
      "Now on 'AACOpenNewWorld.pdf'. . . \"AACOpenNewW\"... already exists\n",
      "\n",
      "Now on 'aar.pdf'. . . \"aar.txt\" already exists\n",
      "\n",
      "Now on 'Abrahamian_E.pdf'. . . \"Abrahamian_\"... already exists\n",
      "\n",
      "Now on 'AccessibilitySoHard.pdf'. . . \"Accessibili\"... already exists\n",
      "\n",
      "Now on 'AchievingKaiserPermanenteQuality2016McHugh.pdf'. . . \"AchievingKa\"... already exists\n",
      "\n",
      "Now on 'AcquiringMastery.pdf'. . . \"AcquiringMa\"... already exists\n",
      "\n",
      "Now on 'Acquity_Group_Whitepaper_-_The_Emerging_Retailer_Guide.pdf'. . . \"Acquity_Gro\"... already exists\n",
      "\n",
      "Now on 'acsc99.pdf'. . . \"acsc99.txt\" already exists\n",
      "\n",
      "PDF to Text was stopped after 25 documents.\n"
     ]
    }
   ],
   "source": [
    "# Pre-condition: All PDF files to be processed are in the sub-directory\n",
    "#     pdfDir, and pdfDir is in absPath. absPath is by default the \n",
    "#     directory in which the program is executed\n",
    "# Post-condition: All PDF files processed without error are converted to\n",
    "#     text files which are placed in a new sub-directory 'Text Files'\n",
    "def pdfToText(pdfDir, absPath = os.getcwd(), txtDir = txtFilesDir):\n",
    "    pdfDirectory = absPath+'/'+pdfDir\n",
    "    txtDirectory = absPath+'/'+txtDir\n",
    "    if pdfDir not in os.listdir(absPath):\n",
    "        print('The specified directory \"' + directory + '\" does not exist')\n",
    "        return\n",
    "# Creates 'Text Files' directory for converted PDFs\n",
    "    if txtDir not in os.listdir(absPath):\n",
    "        os.mkdir(txtDirectory)\n",
    "    \n",
    "    docNum = 0\n",
    "    stopAt = 25\n",
    "    totalNum = len([file for file in os.scandir(pdfDirectory) if file.name.endswith('.pdf')])\n",
    "    with open(absPath+'/'+'log.txt', 'a+', encoding=\"utf-8\") as log:\n",
    "        log.write(\"PDF to Text\\n\" + date.today().strftime(\"%m/%d/%y\") +\n",
    "                  \" at \" + datetime.now().strftime(\"%H:%M:%S\") + \"\\n\\n\")        \n",
    "# Moves on to next entity if the current entity is not a PDF\n",
    "        for entity in os.scandir(pdfDirectory):\n",
    "            if not entity.name.endswith('.pdf') or entity.name[0] in '1234567890':\n",
    "                continue\n",
    "            docNum += 1\n",
    "            index = -4 # Remove '.pdf' from file name when creating '.txt' file\n",
    "            fileName = entity.name[:index]+'.txt'\n",
    "            print(\"Now on '\"+entity.name+\"'. . . \", end='')\n",
    "            \n",
    "# This block attempts to read the PDF file, extract text from each page,\n",
    "#     and write the text to a text file with the same name\n",
    "# Some documents are protected, corrupted, etc. and text cannot be extracted\n",
    "# Exceptions are recorded in log.txt\n",
    "# hasError remains true until each step in the try block is complete\n",
    "            if fileName not in os.listdir(txtDirectory): \n",
    "                hasError = True\n",
    "                with open(pdfDirectory+'/'+entity.name, 'rb') as pdfFileObject:\n",
    "                    try:\n",
    "                        pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "                        numPages = pdfReader.getNumPages()\n",
    "                        pageObject = pdfReader.getPage(0)\n",
    "                        textFile = open(txtDirectory+'/'+fileName, 'a+', encoding=\"utf-8\")\n",
    "                        i = 0;\n",
    "                        while i < numPages:\n",
    "                            pageObject = pdfReader.getPage(i)\n",
    "                            textFile.write(pageObject.extractText())\n",
    "                            i += 1\n",
    "                        print(\"done\\n\")\n",
    "                        hasError = False\n",
    "#                     except TypeError as e:\n",
    "#                         log.write(\"TypeError: \" + entity.name + \":\\n\" + str(e))\n",
    "#                     except PyPDF2.utils.PdfReadError as e:\n",
    "#                         log.write(\"PdfReadError: \" + entity.name + \":\\n\" + str(e))\n",
    "#                     except OSError as e:\n",
    "#                         log.write(\"OSError: \" + entity.name + \":\\n\" + str(e))\n",
    "#                     except decimal.InvalidOperation as e:\n",
    "#                         log.write(\"InvalidOperation: \" + entity.name + \":\\n\" + str(e))\n",
    "                    except Exception as e:\n",
    "                        log.write(str(docNum)+\": \" + entity.name + \": \\n\\t\" + str(e)+\"\\n\")\n",
    "                        textFile.close()\n",
    "                        os.remove(txtDirectory+'/'+fileName)\n",
    "                    pdfFileObject.close()\n",
    "\n",
    "                if hasError:\n",
    "                    print(\"there was an error reading this document. See log for details. Reference number \"+str(docNum)+\".\\n\")\n",
    "            else:\n",
    "                max = 10\n",
    "                if len(fileName) > max:\n",
    "                    print('\"'+fileName[:11]+'\"' + '...', end='')\n",
    "                else:\n",
    "                    print('\"'+fileName+'\"', end='')\n",
    "                print(' already exists\\n')\n",
    "            if docNum == stopAt:\n",
    "                print(\"PDF to Text was stopped after \"+str(docNum)+\" documents.\")\n",
    "                break\n",
    "        log.write(\"\\n\\n\")\n",
    "pdfToText('PDF', absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on 10 (good) files at a time until pipeline works\n",
    "#   then incrementally add files and clean up errors\n",
    "\n",
    "# Function to remove \\n\n",
    "filesDir = 'Text Files'\n",
    "def rmvN(filesDir = txtFilesDir, absPath = os.getcwd()):\n",
    "    directory = absPath+'/'+filesDir\n",
    "    if filesDir not in os.listdir(absPath):\n",
    "        print('The specified directory \"' + directory + '\" does not exist')\n",
    "        return\n",
    "    for entity in os.scandir(directory):\n",
    "        with open(directory+'/'+entity.name, 'r+', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            text = re.sub('-\\n', '', text)\n",
    "            text = re.sub('\\n', '', text)\n",
    "            f.seek(0)\n",
    "            f.write(text)\n",
    "            f.truncate()\n",
    "rmvN(filesDir, absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Funtion to move files without spaces to new 'Without Spaces' directory         \n",
    "def checkSpaces(filesDir = txtFilesDir, absPath = os.getcwd()):\n",
    "    directory = absPath+'/'+filesDir\n",
    "    if filesDir not in os.listdir(absPath):\n",
    "        print('The specified directory \"' + directory + '\" does not exist')\n",
    "        return\n",
    "    wsDir = 'Without Spaces'\n",
    "    if wsDir not in os.listdir(absPath):\n",
    "        os.mkdir(absPath+'/'+wsDir)\n",
    "        \n",
    "    with open(absPath+'/'+'No Spaces.txt', 'a+', encoding='utf-8') as noSpaces: \n",
    "        noSpaces.write(\"Check Spaces\\n\" + date.today().strftime(\"%m/%d/%y\") +\n",
    "                  \" at \" + datetime.now().strftime(\"%H:%M:%S\") + \"\\n\\n\")\n",
    "        for entity in os.scandir(directory):\n",
    "            f = open(directory+'/'+entity.name, 'r', encoding='utf-8')\n",
    "            text = f.read()\n",
    "            split = text.split(' ')\n",
    "            if len(split) < len(text)/10 or text == '':\n",
    "                f.close()\n",
    "                noSpaces.write(entity.name+'\\n')\n",
    "                if entity.name not in os.listdir(absPath+'/'+wsDir):\n",
    "                    os.rename(directory+'/'+entity.name, absPath+'/'+wsDir+'/'+entity.name)  \n",
    "        noSpaces.write('\\n\\n')\n",
    "checkSpaces(filesDir, absolute) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords\n",
    "# NLTK or SpaCy\n",
    "# Inverted File: gram:[doc1, doc3] or gram:[[doc1,freq], [doc3,freq]]\n",
    "def rmvStopWords(nlp, filesDir = txtFilesDir, absPath = os.getcwd()):\n",
    "    directory = absPath+'/'+filesDir\n",
    "    exists = False\n",
    "    for entity in os.scandir(absPath):\n",
    "        if entity.is_dir() and entity.name == filesDir:\n",
    "            exists = True\n",
    "    if not exists:\n",
    "        print('The specified directory \"' + directory + '\" does not exist')\n",
    "        return\n",
    "    for entity in os.scandir(absPath+'/'+filesDir):\n",
    "        with open(directory+'/'+entity.name, 'r+', encoding='utf-8') as f:\n",
    "            doc = nlp(f.read())\n",
    "            noStopWords = [stemmer.stem(token.lemma_.lower()) for token in doc if not token.is_stop and not token.is_punct]\n",
    "#             Quotation marks appear as 'fi' in text files (merged with words)\n",
    "#             maybe compare to words that start with fi\n",
    "            f.seek(0)\n",
    "            f.write(\" \".join(noStopWords))\n",
    "            #                 f.write(token.orth_.lower() + ' ')\n",
    "            f.truncate()\n",
    "\n",
    "rmvStopWords(nlp, filesDir, absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to stem words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity score for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram parser-based inverted file \n",
    "# (TF-DIF to remove trigrams common to most or all documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering algorithm based on trigram inverted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bigram parser-based info to inverted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement clustering on bigram inverted file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
