{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future improvements\n",
    "# Create JSON array to assign IDs, \n",
    "#     keep track of PDF files process (each step?) etc.\n",
    "# Implement 'fi'/'fl' check at beginning and end of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os # For file/directory interaction\n",
    "import time, sys\n",
    "import PyPDF2 # Library for converting PDF to text\n",
    "from datetime import datetime, date # For log data\n",
    "import decimal # Exceptions caught from this package\n",
    "import re # For text replacement\n",
    "import spacy # Pipeline processes (stopword and punctuation removal, lemmatization)\n",
    "from nltk.stem.snowball import SnowballStemmer # Pipeline process for stemming\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "txtFilesDir = 'Text Files'\n",
    "absolute = 'C:/Users/micah/Documents/IWU/CIS Practicum/Files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on 'A  cognitive affective model of organizational communication for designing IT.pdf'. . . \"A  cognitiv\"... already exists\n",
      "\n",
      "Now on 'A Bible for the Disability Field.pdf'. . . \"A Bible for\"... already exists\n",
      "\n",
      "Now on 'A Comparisoon of Binarization Methods for Historical Archive Documents.pdf'. . . \"A Compariso\"... already exists\n",
      "\n",
      "Now on 'A light-weight text image processing method for handheld embedded cameras.pdf'. . . \"A light-wei\"... already exists\n",
      "\n",
      "Now on 'A Mathematical Theory of Communication.pdf'. . . \"A Mathemati\"... already exists\n",
      "\n",
      "Now on 'A Model for Types and Levels of Human Interaction with Automation.pdf'. . . \"A Model for\"... already exists\n",
      "\n",
      "Now on 'A Parser for Real-Time Speech Synthesis of Conversational Texts.pdf'. . . \"A Parser fo\"... already exists\n",
      "\n",
      "Now on 'A Physically Based Approach to 2-D Shape Blending.pdf'. . . there was an error reading this document. See log for details. Reference number 8.\n",
      "\n",
      "Now on 'A Review of 326 Children with Developmental and Physical Disabilities, Consecutively Taught at the Movement Development Clinic.pdf'. . . \"A Review of\"... already exists\n",
      "\n",
      "Now on 'A Review of Quasi-Linear Pilot Models.pdf'. . . \"A Review of\"... already exists\n",
      "\n",
      "Now on 'A Set of C++ Classes for Co-routine Style Programming.pdf'. . . \"A Set of C+\"... already exists\n",
      "\n",
      "Now on 'A Spiral Model of Software Development and Enhancement.pdf'. . . there was an error reading this document. See log for details. Reference number 12.\n",
      "\n",
      "Now on 'A Study of Design Requirements for Mobile Learning Environments.pdf'. . . \"A Study of \"... already exists\n",
      "\n",
      "Now on 'A Target Tracking Algorithm of Passive Sensor Normal Truncated Model.pdf'. . . \"A Target Tr\"... already exists\n",
      "\n",
      "Now on 'a12.pdf'. . . \"a12.txt\" already exists\n",
      "\n",
      "Now on 'a2-jeong.pdf'. . . \"a2-jeong.tx\"... already exists\n",
      "\n",
      "Now on 'a2.pdf'. . . \"a2.txt\" already exists\n",
      "\n",
      "Now on 'AACOpenNewWorld.pdf'. . . \"AACOpenNewW\"... already exists\n",
      "\n",
      "Now on 'aar.pdf'. . . \"aar.txt\" already exists\n",
      "\n",
      "Now on 'Abrahamian_E.pdf'. . . \"Abrahamian_\"... already exists\n",
      "\n",
      "Now on 'AccessibilitySoHard.pdf'. . . \"Accessibili\"... already exists\n",
      "\n",
      "Now on 'AchievingKaiserPermanenteQuality2016McHugh.pdf'. . . \"AchievingKa\"... already exists\n",
      "\n",
      "Now on 'AcquiringMastery.pdf'. . . \"AcquiringMa\"... already exists\n",
      "\n",
      "Now on 'Acquity_Group_Whitepaper_-_The_Emerging_Retailer_Guide.pdf'. . . \"Acquity_Gro\"... already exists\n",
      "\n",
      "Now on 'acsc99.pdf'. . . \"acsc99.txt\" already exists\n",
      "\n",
      "Now on 'Acting_to_know_improving_creativity_in_t.pdf'. . . \"Acting_to_k\"... already exists\n",
      "\n",
      "Now on 'ActionInResearch.pdf'. . . \"ActionInRes\"... already exists\n",
      "\n",
      "Now on 'ActorModelOfComputation.pdf'. . . \"ActorModelO\"... already exists\n",
      "\n",
      "Now on 'Adam - A Method for Stochastic Optimization.pdf'. . . \"Adam - A Me\"... already exists\n",
      "\n",
      "Now on 'AdaptiveDecisionSupport.pdf'. . . there was an error reading this document. See log for details. Reference number 30.\n",
      "\n",
      "Now on 'AdaptiveFinancial.pdf'. . . done\n",
      "\n",
      "Now on 'AddingReinforcedCorners.pdf'. . . done\n",
      "\n",
      "Now on 'AddingU-CDToAgileDevelopment.pdf'. . . done\n",
      "\n",
      "Now on 'Adoption Agreement - Keefer.pdf'. . . there was an error reading this document. See log for details. Reference number 34.\n",
      "\n",
      "Now on 'ADSS_B2C.pdf'. . . done\n",
      "\n",
      "Now on 'ADSS_keefer.pdf'. . . done\n",
      "\n",
      "Now on 'AdvertisingGetsPersonal.pdf'. . . done\n",
      "\n",
      "Now on 'Advice on Conducting the Scrum of Scrums Meeting - Scrum Alliance.pdf'. . . done\n",
      "\n",
      "Now on 'Aesthetics.pdf'. . . there was an error reading this document. See log for details. Reference number 39.\n",
      "\n",
      "Now on 'AestheticsOfReading.pdf'. . . done\n",
      "\n",
      "Now on 'af073.pdf'. . . done\n",
      "\n",
      "Now on 'AffectiveVirtualPatientTESI05.pdf'. . . done\n",
      "\n",
      "Now on 'Affordances and Design.pdf'. . . done\n",
      "\n",
      "Now on 'Affordances.pdf'. . . done\n",
      "\n",
      "Now on 'afteraccess_chi2010_prepub.pdf'. . . done\n",
      "\n",
      "Now on 'AFunctionalStyle.pdf'. . . done\n",
      "\n",
      "Now on 'Agents of Alienation.pdf'. . . done\n",
      "\n",
      "Now on 'Agile Development for Competitive Advantage.pdf'. . . done\n",
      "\n",
      "Now on 'Agile Meetings.pdf'. . . done\n",
      "\n",
      "Now on 'Agile Software Process and Its Experience.pdf'. . . done\n",
      "\n",
      "Now on 'Agile UX.pdf'. . . done\n",
      "\n",
      "Now on 'Agile-version-control-with-multiple-teams.pdf'. . . done\n",
      "\n",
      "Now on 'agile2005_cyrusinnovation_targetcostcontracts_paper.pdf'. . . done\n",
      "\n",
      "Now on 'AgileAndSecure_SanAntonioAITP_20070815.pdf'. . . done\n",
      "\n",
      "Now on 'agiledesign.pdf'. . . done\n",
      "\n",
      "Now on 'AgileMethodsGoodForDesign.pdf'. . . done\n",
      "\n",
      "Now on 'AgileSoftwareBottomLine.pdf'. . . done\n",
      "\n",
      "Now on 'AgileSoftwareDevelopment.pdf'. . . done\n",
      "\n",
      "Now on 'AgileStrategy.pdf'. . . done\n",
      "\n",
      "Now on 'Agile_Methods_Perspective_ARR_John_Manzo.pdf'. . . done\n",
      "\n",
      "Now on 'Agile_The_UCD_Perspective.pdf'. . . done\n",
      "\n",
      "Now on 'agile_times_7.pdf'. . . done\n",
      "\n",
      "Now on 'agile_times__7.pdf'. . . done\n",
      "\n",
      "Now on 'agile_usability_2nd_edition.pdf'. . . done\n",
      "\n",
      "Now on 'AgingPopulation.pdf'. . . done\n",
      "\n",
      "Now on 'AI-and-Cognitive-Computing.pdf'. . . done\n",
      "\n",
      "Now on 'AIsolutionManual.pdf'. . . done\n",
      "\n",
      "Now on 'aj6103266.pdf'. . . done\n",
      "\n",
      "Now on 'al hashal - final.pdf'. . . done\n",
      "\n",
      "Now on 'al hashal.pdf'. . . done\n",
      "\n",
      "Now on 'AlanAndI.pdf'. . . done\n",
      "\n",
      "Now on 'albert.pdf'. . . done\n",
      "\n",
      "Now on 'Align What.pdf'. . . done\n",
      "\n",
      "Now on 'All Those Opposed.pdf'. . . done\n",
      "\n",
      "Now on 'AllarmSettingsReduceFatigue.pdf'. . . done\n",
      "\n",
      "Now on 'AlwaysGoodTuring.pdf'. . . done\n",
      "\n",
      "Now on 'AMA_ROIWhitePaper_28Feb02[1].pdf'. . . done\n",
      "\n",
      "Now on 'AmbientIntChallengesAndRecom.pdf'. . . done\n",
      "\n",
      "Now on 'AmbientIntelligence.pdf'. . . done\n",
      "\n",
      "Now on 'AmbientTouchTactileHandheld.pdf'. . . done\n",
      "\n",
      "Now on 'Ambient_Inteligence.pdf'. . . done\n",
      "\n",
      "Now on 'Amended and Restated Operating Agreement.pdf'. . . done\n",
      "\n",
      "Now on 'AMIA-0164-S2007.pdf'. . . done\n",
      "\n",
      "Now on 'AmIReportFinal.pdf'. . . done\n",
      "\n",
      "Now on 'An Initial Investigation of Test Driven Development in Industry.pdf'. . . done\n",
      "\n",
      "Now on 'An Introduction To Statistical Learning with Applications in R.pdf'. . . done\n",
      "\n",
      "Now on 'Analyzing error-prone system structure.pdf'. . . done\n",
      "\n",
      "Now on 'AnAngleOnlyTrackingFilterInModifiedSphericalCoordinates.pdf'. . . done\n",
      "\n",
      "Now on 'AnAngleOnlyTrackingFilterInModifiedSphericalCoordinates_Amendum.pdf'. . . there was an error reading this document. See log for details. Reference number 89.\n",
      "\n",
      "Now on 'AnatomyDesignSession.pdf'. . . done\n",
      "\n",
      "Now on 'ANNPR03.pdf'. . . done\n",
      "\n",
      "Now on 'AnswerLab Great Voice Experiences Start with Listening.pdf'. . . done\n",
      "\n",
      "Now on 'Anthem Approval Letter.pdf'. . . done\n",
      "\n",
      "Now on 'Anthem Policy.pdf'. . . done\n",
      "\n",
      "Now on 'AnxietyDecision-Making.pdf'. . . done\n",
      "\n",
      "Now on 'Appendix E_Care Plan Exchange Report.pdf'. . . done\n",
      "\n",
      "Now on 'Application for Employer Identification Number.pdf'. . . done\n",
      "\n",
      "Now on 'Application of Natural Language Processing Techniques to Marine V-22 Maintenance Data for Populating a CBM-Oriented Database.pdf'. . . done\n",
      "\n",
      "Now on 'Apply Demand-Resource Framework.pdf'. . . done\n",
      "\n",
      "Now on 'ApplySocialMedia.pdf'. . . done\n",
      "\n",
      "Now on 'AppropriateAgileMeasurement.pdf'. . . done\n",
      "\n",
      "Now on 'AR-motor-disabilities.pdf'. . . done\n",
      "\n",
      "Now on 'ArbitWarped.pdf'. . . done\n",
      "\n",
      "Now on 'ArchOptimization.pdf'. . . done\n",
      "\n",
      "Now on 'AReviewTechnology-BasedApproaches_final.pdf'. . . done\n",
      "\n",
      "Now on 'Are_We_Doing_Well.pdf'. . . done\n",
      "\n",
      "Now on 'ArgumentforSelfCare.pdf'. . . done\n",
      "\n",
      "Now on 'ArgumentsAndResults.pdf'. . . there was an error reading this document. See log for details. Reference number 108.\n",
      "\n",
      "Now on 'Art.pdf'. . . done\n",
      "\n",
      "Now on 'article.pdf'. . . done\n",
      "\n",
      "Now on 'articles_001.pdf'. . . done\n",
      "\n",
      "Now on 'Article_Secret to Success_UX.pdf'. . . done\n",
      "\n",
      "Now on 'ArtificialCreativity.pdf'. . . done\n",
      "\n",
      "Now on 'Ask_Nancy_2012.pdf'. . . done\n",
      "\n",
      "Now on 'Assessing Test-Driven Development at IBM.pdf'. . . done\n",
      "\n",
      "Now on 'Asset Failure Prediction.pdf'. . . done\n",
      "\n",
      "Now on 'AssistedUser.pdf'. . . done\n",
      "\n",
      "Now on 'AssistSocialInter.pdf'. . . done\n",
      "\n",
      "Now on 'astar.pdf'. . . done\n",
      "\n",
      "Now on 'AsWeMayThink.pdf'. . . done\n",
      "\n",
      "Now on 'ATK_Manual.pdf'. . . done\n",
      "\n",
      "Now on 'AtomicDesign.pdf'. . . done\n",
      "\n",
      "Now on 'ATOutcomesAndBenefits.pdf'. . . done\n",
      "\n",
      "Now on 'Attacks Meet Interpretability.pdf'. . . done\n",
      "\n",
      "Now on 'Attitudes.pdf'. . . done\n",
      "\n",
      "Now on 'Attribute-Grammars.pdf'. . . done\n",
      "\n",
      "Now on 'AuditoryNavigation.pdf'. . . there was an error reading this document. See log for details. Reference number 127.\n",
      "\n",
      "Now on 'Augmented Reality in Educational Inclusion. A Systematic Review on the Last Decade.pdf'. . . done\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on 'Augmented Reality Platform for Mass Casualty Incidents.pdf'. . . done\n",
      "\n",
      "Now on 'Aural Information Architectures.pdf'. . . done\n",
      "\n",
      "Now on 'AutobiographicalDesign.pdf'. . . done\n",
      "\n",
      "Now on 'Automatic Evaluation of Document Binarization Results.pdf'. . . done\n",
      "\n",
      "Now on 'AutomaticPageAnalysis.pdf'. . . done\n",
      "\n",
      "Now on 'Automation Induced Complacency.pdf'. . . done\n",
      "\n",
      "Now on 'Avios-DSR-paper.pdf'. . . done\n",
      "\n",
      "Now on 'awfechallengeoreilly.pdf'. . . done\n",
      "\n",
      "Now on 'A_Guide_to_Clinical_Engineering.pdf'. . . done\n",
      "\n",
      "Now on 'A_rational_design_process_How_and_why_to_fake_it.pdf'. . . done\n",
      "\n",
      "Now on 'A_Survey_of_the_Hough_Transform.pdf'. . . done\n",
      "\n",
      "Now on 'BachmanInventedDBMS.pdf'. . . done\n",
      "\n",
      "Now on 'BadSoftwareArchitectue is a People Problem.pdf'. . . done\n",
      "\n",
      "Now on 'Baltes_Boris_B.pdf'. . . done\n",
      "\n",
      "Now on 'BDA.pdf'. . . done\n",
      "\n",
      "Now on 'Bearings-only maneuvering target tracking based on truncated quadrature Kalman filtering.pdf'. . . done\n",
      "\n",
      "Now on 'Bearings-Only Tracking Using Augmented Ensemble Kalman Filter.pdf'. . . done\n",
      "\n",
      "Now on 'Beating-Common-Sense.pdf'. . . done\n",
      "\n",
      "Now on 'BeautifulOutlaw_ParticipantsGuide.pdf'. . . done\n",
      "\n",
      "Now on 'Beauty.pdf'. . . done\n",
      "\n",
      "Now on 'Beecher_Valerie.pdf'. . . done\n",
      "\n",
      "Now on 'Behavior.pdf'. . . done\n",
      "\n",
      "PDF to Text was stopped after 150 documents.\n"
     ]
    }
   ],
   "source": [
    "# Pre-condition: All PDF files to be processed are in the sub-directory\n",
    "#     pdfDir, and pdfDir is in absPath. absPath is by default the \n",
    "#     directory in which the program is executed\n",
    "# Post-condition: All PDF files processed without error are converted to\n",
    "#     text files which are placed in a new sub-directory 'Text Files'\n",
    "def pdfToText(pdfDir, absPath = os.getcwd(), txtDir = txtFilesDir):\n",
    "    pdfDirectory = absPath+'/'+pdfDir\n",
    "    txtDirectory = absPath+'/'+txtDir\n",
    "    if pdfDir not in os.listdir(absPath):\n",
    "        print('The specified directory \"' + directory + '\" does not exist')\n",
    "        return\n",
    "# Creates 'Text Files' directory for converted PDFs\n",
    "    if txtDir not in os.listdir(absPath):\n",
    "        os.mkdir(txtDirectory)\n",
    "    \n",
    "    docNum = 0\n",
    "    stopAt = 150\n",
    "    totalNum = len([file for file in os.scandir(pdfDirectory) if file.name.endswith('.pdf')])\n",
    "    with open(absPath+'/'+'log.txt', 'a+', encoding=\"utf-8\") as log:\n",
    "        log.write(\"PDF to Text\\n\" + date.today().strftime(\"%m/%d/%y\") +\n",
    "                  \" at \" + datetime.now().strftime(\"%H:%M:%S\") + \"\\n\\n\")        \n",
    "# Moves on to next entity if the current entity is not a PDF\n",
    "        for entity in os.scandir(pdfDirectory):\n",
    "            if not entity.name.endswith('.pdf') or entity.name[0] in '1234567890':\n",
    "                continue\n",
    "            docNum += 1\n",
    "            index = -4 # Remove '.pdf' from file name when creating '.txt' file\n",
    "            fileName = entity.name[:index]+'.txt'\n",
    "            print(\"Now on '\"+entity.name+\"'. . . \", end='')\n",
    "            \n",
    "# This block attempts to read the PDF file, extract text from each page,\n",
    "#     and write the text to a text file with the same name\n",
    "# Some documents are protected, corrupted, etc. and text cannot be extracted\n",
    "# Exceptions are recorded in log.txt\n",
    "# hasError remains true until each step in the try block is complete\n",
    "            if fileName not in os.listdir(txtDirectory): \n",
    "                hasError = True\n",
    "                with open(pdfDirectory+'/'+entity.name, 'rb') as pdfFileObject:\n",
    "                    try:\n",
    "                        pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "                        numPages = pdfReader.getNumPages()\n",
    "                        pageObject = pdfReader.getPage(0)\n",
    "                        textFile = open(txtDirectory+'/'+fileName, 'a+', encoding=\"utf-8\")\n",
    "                        i = 0;\n",
    "                        while i < numPages:\n",
    "                            pageObject = pdfReader.getPage(i)\n",
    "                            textFile.write(pageObject.extractText())\n",
    "                            i += 1\n",
    "                        print(\"done\\n\")\n",
    "                        hasError = False\n",
    "#                     except TypeError as e:\n",
    "#                         log.write(\"TypeError: \" + entity.name + \":\\n\" + str(e))\n",
    "#                     except PyPDF2.utils.PdfReadError as e:\n",
    "#                         log.write(\"PdfReadError: \" + entity.name + \":\\n\" + str(e))\n",
    "#                     except OSError as e:\n",
    "#                         log.write(\"OSError: \" + entity.name + \":\\n\" + str(e))\n",
    "#                     except decimal.InvalidOperation as e:\n",
    "#                         log.write(\"InvalidOperation: \" + entity.name + \":\\n\" + str(e))\n",
    "                    except Exception as e:\n",
    "                        log.write(str(docNum)+\": \" + entity.name + \": \\n\\t\" + str(e)+\"\\n\")\n",
    "                        textFile.close()\n",
    "                        if fileName in os.listdir(txtDirectory):\n",
    "                            os.remove(txtDirectory+'/'+fileName)\n",
    "                    pdfFileObject.close()\n",
    "\n",
    "                if hasError:\n",
    "                    print(\"there was an error reading this document. See log for details. Reference number \"+str(docNum)+\".\\n\")\n",
    "            else:\n",
    "                max = 10\n",
    "                if len(fileName) > max:\n",
    "                    print('\"'+fileName[:11]+'\"' + '...', end='')\n",
    "                else:\n",
    "                    print('\"'+fileName+'\"', end='')\n",
    "                print(' already exists\\n')\n",
    "            if docNum == stopAt:\n",
    "                print(\"PDF to Text was stopped after \"+str(docNum)+\" documents.\")\n",
    "                break\n",
    "        log.write(\"\\n\\n\")\n",
    "pdfToText('PDF', absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on 10 (good) files at a time until pipeline works\n",
    "#   then incrementally add files and clean up errors\n",
    "\n",
    "# Function to remove \\n\n",
    "filesDir = 'Text Files'\n",
    "def rmvN(filesDir = txtFilesDir, absPath = os.getcwd()):\n",
    "    directory = absPath+'/'+filesDir\n",
    "    if filesDir not in os.listdir(absPath):\n",
    "        print('The specified directory \"' + directory + '\" does not exist')\n",
    "        return\n",
    "    for entity in os.scandir(directory):\n",
    "        with open(directory+'/'+entity.name, 'r+', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            text = re.sub('-\\n', '', text)\n",
    "            text = re.sub('\\n', '', text)\n",
    "            f.seek(0)\n",
    "            f.write(text)\n",
    "            f.truncate()\n",
    "rmvN(filesDir, absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Funtion to move files without spaces to new 'Without Spaces' directory         \n",
    "def checkSpaces(filesDir = txtFilesDir, absPath = os.getcwd()):\n",
    "    directory = absPath+'/'+filesDir\n",
    "    if filesDir not in os.listdir(absPath):\n",
    "        print('The specified directory \"' + directory + '\" does not exist')\n",
    "        return\n",
    "    wsDir = 'Without Spaces'\n",
    "    if wsDir not in os.listdir(absPath):\n",
    "        os.mkdir(absPath+'/'+wsDir)\n",
    "        \n",
    "    with open(absPath+'/'+'No Spaces.txt', 'a+', encoding='utf-8') as noSpaces: \n",
    "        noSpaces.write(\"Check Spaces\\n\" + date.today().strftime(\"%m/%d/%y\") +\n",
    "                  \" at \" + datetime.now().strftime(\"%H:%M:%S\") + \"\\n\\n\")\n",
    "        for entity in os.scandir(directory):\n",
    "            f = open(directory+'/'+entity.name, 'r', encoding='utf-8')\n",
    "            text = f.read()\n",
    "            split = text.split(' ')\n",
    "            if len(split) < len(text)/10 or text == '':\n",
    "                f.close()\n",
    "                noSpaces.write(entity.name+'\\n')\n",
    "                if entity.name not in os.listdir(absPath+'/'+wsDir):\n",
    "                    os.rename(directory+'/'+entity.name, absPath+'/'+wsDir+'/'+entity.name)\n",
    "                else:\n",
    "                    os.remove(directory+'/'+entity.name)\n",
    "        noSpaces.write('\\n\\n')\n",
    "checkSpaces(filesDir, absolute) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords\n",
    "# NLTK or SpaCy\n",
    "# Inverted File: gram:[doc1, doc3] or gram:[[doc1,freq], [doc3,freq]]\n",
    "def rmvStopWords(nlp, filesDir = txtFilesDir, absPath = os.getcwd()):\n",
    "    directory = absPath+'/'+filesDir\n",
    "    if filesDir not in os.listdir(absPath):\n",
    "        print('The specified directory \"' + directory + '\" does not exist')\n",
    "        return\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    for entity in os.scandir(absPath+'/'+filesDir):\n",
    "        with open(directory+'/'+entity.name, 'r+', encoding='utf-8') as f:\n",
    "            doc = nlp(f.read())\n",
    "            noStopWords = [stemmer.stem(token.lemma_.lower()) for token in doc if not token.is_stop and not token.is_punct]\n",
    "#             noStopWords = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "#             Quotation marks appear as 'fi' in text files (merged with words)\n",
    "#             maybe compare to words that start with fi\n",
    "            f.seek(0)\n",
    "            f.write(\" \".join(noStopWords))\n",
    "            #                 f.write(token.orth_.lower() + ' ')\n",
    "            f.truncate()\n",
    "\n",
    "rmvStopWords(nlp, filesDir, absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words : \n",
      "                               term      rank\n",
      "117746         cohn editormik cohn  1.303682\n",
      "173640    editormik cohn editormik  0.977762\n",
      "5136                      11 11 11  0.641984\n",
      "397587            scrum scrum meet  0.496957\n",
      "66811         agil softwar develop  0.494473\n",
      "71798    ambient intellig everyday  0.481594\n",
      "390607    roadmap ambient intellig  0.474334\n",
      "185258        esto roadmap ambient  0.471914\n",
      "70                        00 pm 00  0.467379\n",
      "341521                    pm 00 pm  0.467379\n",
      "83937      assist technolog outcom  0.460861\n",
      "168510           docu my 20earticl  0.450071\n",
      "302678       my 20earticl emmerson  0.450071\n",
      "471344          usag center design  0.442381\n",
      "148659        decis support system  0.428163\n",
      "446562    technolog outcom benefit  0.421394\n",
      "0                         00 00 00  0.415448\n",
      "28166                  30 jan 2017  0.408248\n",
      "8785                1412 6980v9 cs  0.408248\n",
      "270094                   lg 30 jan  0.408248\n",
      "44311                 6980v9 cs lg  0.408248\n",
      "82237            arxiv 1412 6980v9  0.408248\n",
      "142016                    cs lg 30  0.408248\n",
      "427058         strateg data system  0.398799\n",
      "469012             unit state 2005  0.386304\n",
      "441553        target cost contract  0.384460\n",
      "21439                 2006 vol num  0.358633\n",
      "195726               fall 2006 vol  0.358633\n",
      "6402                      12 12 12  0.341920\n",
      "3483                      10 10 10  0.333379\n",
      "216337                good ps valu  0.332201\n",
      "181314        eni organiz communic  0.322291\n",
      "366731              quarter vol 25  0.322291\n",
      "482257                 vol 25 june  0.317093\n",
      "261356     kleimann communic group  0.315881\n",
      "43092                65 unit state  0.315507\n",
      "3121                      09 09 09  0.311586\n",
      "283006         maneuv target track  0.305339\n",
      "95227   berczuk editorstev berczuk  0.305117\n",
      "63869                 af mil af073  0.302554\n",
      "60709          adapt decis support  0.301059\n",
      "120504    commerci militari applic  0.297426\n",
      "471808       use commerci militari  0.297426\n",
      "170889           dual use commerci  0.297426\n",
      "121654       communic group consum  0.293318\n",
      "218886          group consum union  0.293318\n",
      "270317             licens http www  0.290344\n",
      "230358             http www flickr  0.290344\n",
      "203333           flickr com photos  0.290344\n",
      "494431              www flickr com  0.290344\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity score for each document\n",
    "def tfdif_cossim(filesDir = txtFilesDir, absPath = os.getcwd()):\n",
    "    directory = absPath+'/'+filesDir\n",
    "    if filesDir not in os.listdir(absPath):\n",
    "        print('The specified directory \"' + directory + '\" does not exist')\n",
    "        return\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(3,3), stop_words=None, use_idf=True)\n",
    "    X2 = vectorizer.fit_transform([open(directory+'/'+file, \"r\", encoding='utf-8').read() for file in os.listdir(directory)])\n",
    "#     X2 = vectorizer.fit_transform(open(directory+'/'+'A Bible for the Disability Field.txt', 'r', encoding='utf-8'))\n",
    "    features = vectorizer.get_feature_names()\n",
    "#     print(features)\n",
    "    scores = (X2.toarray()) \n",
    "#     print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "    # Getting top ranking features \n",
    "    sums = X2.sum(axis = 0) \n",
    "    data1 = [] \n",
    "    for col, term in enumerate(features): \n",
    "        data1.append( (term, sums[0, col] )) \n",
    "    ranking = pd.DataFrame(data1, columns = ['term', 'rank']) \n",
    "    words = (ranking.sort_values('rank', ascending = False)) \n",
    "    print (\"\\n\\nWords : \\n\", words.head(50)) \n",
    "    \n",
    "tfdif_cossim(filesDir, absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram parser-based inverted file \n",
    "# (TF-DIF to remove trigrams common to most or all documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering algorithm based on trigram inverted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bigram parser-based info to inverted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement clustering on bigram inverted file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
